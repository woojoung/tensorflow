{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorpack tutorial by Pamo\n",
    "#### In this tutorial, we are going to cover following steps.\n",
    "* **Data Loading** (Dataflow)\n",
    "* **Build a model**\n",
    "* **Training & test** (CPU, GPU, or MultiGPU)\n",
    "* **Trasfer learning** (Loading a saved Model and training it agiain)\n",
    "* **Evaluation** (Loading a saved Model and test it)\n",
    "\n",
    "#### You can find more specific explanations per function in [here](https://tensorpack.readthedocs.io/modules/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaeujeong/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/chaeujeong/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/Users/chaeujeong/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/chaeujeong/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/chaeujeong/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/chaeujeong/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/chaeujeong/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import cv2 # for using AugmentImageComponent\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tensorpack import *\n",
    "from tensorpack.dataflow import *\n",
    "from tensorpack.tfutils import summary\n",
    "#from tensorpack.utils.stats import RatioCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "삼항연산자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bool_is_train = is_train == 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_is_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get DataFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataflow(batch_size, is_train='train'): # str type\n",
    "    # bool_is_train = is_train == 'train' : 우리는 T/F로 코딩을 하는 경우가 많다. \n",
    "    df = dataset.Mnist(is_train, shuffle=True) # return type: dataflow(df)\n",
    "\n",
    "    # ----- Image Augmentation Options -------- #\n",
    "    if is_train is 'train':\n",
    "        augs = [\n",
    "            #   imgaug.CenterCrop(256, 256),\n",
    "            #   imgaug.Resize((225, 225)),\n",
    "            #   imgaug.Grayscale(keepdims=True),\n",
    "#                imgaug.Flip(horiz=True, vert=False, prob=0.5),\n",
    "        ]\n",
    "    else:\n",
    "        augs = [\n",
    "            #   imgaug.CenterCrop(256, 256),\n",
    "            #   imgaug.Resize((225, 225)),\n",
    "        ]\n",
    "    df = AugmentImageComponent(df, augs)\n",
    "    # group data into batches of size 128\n",
    "    df = BatchData(df, batch_size)\n",
    "    # start 3 processes to run the dataflow in parallel\n",
    "    # df = PrefetchDataZMQ(df, 10, multiprocessing.cpu_count())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABkAAAAF2CAYAAAA2iFSZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWIAAAAAAAADNsQABAAAAAACa8/8BP1osiCUIhH8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c33f02c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = get_dataflow(4, 'train') #(batch_size, )\n",
    "df.reset_state() # 보통 안해줘도 된다. \n",
    "\n",
    "fig =plt.figure(figsize=(28, 28))\n",
    "\n",
    "for idx, dp in enumerate(df.get_data()):\n",
    "    if idx == 0:\n",
    "        for i in range(4):\n",
    "            img = dp[idx][i]\n",
    "            fig.add_subplot(1, 4, i + 1)\n",
    "            plt.imshow(img, cmap='gray')\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model \n",
    "#### Model includes Loss function & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Description of ModelDesc at\n",
    "# https://tensorpack.readthedocs.io/modules/graph_builder.html#tensorpack.graph_builder.ModelDesc\n",
    "class Model(ModelDesc):\n",
    "    def inputs(self):\n",
    "        \"\"\"\n",
    "        Define input shape\n",
    "        \"\"\"\n",
    "        return [tf.placeholder(tf.float32, [None, 28, 28], 'input'),\n",
    "                tf.placeholder(tf.int32, [None], 'label')]\n",
    "\n",
    "    def build_graph(self, image, label):\n",
    "        \"\"\"\n",
    "        Build the model which takes the input and return cost. \n",
    "        \"\"\"\n",
    "        # NHW to NHWC\n",
    "        image = tf.expand_dims(image, 3)\n",
    "\n",
    "        with argscope(Conv2D, filters=32, kernel_size=3, activation=tf.nn.relu):\n",
    "            with tf.name_scope('layer1') as scope:\n",
    "                layer1 = (LinearWrap(image)\n",
    "                          .Conv2D('conv0')\n",
    "                          .MaxPooling('pool0', 2)\n",
    "                          .Dropout('dropout', rate=0.7)())\n",
    "\n",
    "        with argscope(Conv2D, filters=64, kernel_size=3, activation=tf.nn.relu):\n",
    "            with tf.name_scope('layer2') as scope:\n",
    "                layer2 = (LinearWrap(layer1)\n",
    "                          .Conv2D('conv1')\n",
    "                          .MaxPooling('pool1', 2)\n",
    "                          .Dropout('dropout', rate=0.7)())\n",
    "\n",
    "        with argscope(Conv2D, filters=128, kernel_size=3, activation=tf.nn.relu):\n",
    "            with tf.name_scope('layer3') as scope:\n",
    "                layer3 = (LinearWrap(layer2)\n",
    "                          .Conv2D('conv2')\n",
    "                          .MaxPooling('pool2', 2)\n",
    "                          .Dropout('dropout', rate=0.7)\n",
    "                          .FullyConnected('fc1', units=10,\n",
    "                                          activation=tf.identity)())\n",
    "                \n",
    "        # Cost function\n",
    "        cost = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(logits=layer3, \n",
    "                                                           labels=label),\n",
    "            name='Loss')\n",
    "        \n",
    "        correct = tf.cast(tf.equal(tf.argmax(layer3, -1, \n",
    "                                             output_type=tf.int32), \n",
    "                                   label),\n",
    "                          tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct, name='accuracy')\n",
    "        train_error = tf.reduce_mean(1 - correct, name='train_error')\n",
    "        \n",
    "        summary.add_moving_summary(train_error, accuracy) # 이동평균, 그래프를 스무스하게 그려준다. 경향성, 방향성을 파악하기 쉬워진다. \n",
    "        return cost\n",
    "\n",
    "    def optimizer(self):\n",
    "        lr = tf.train.exponential_decay(\n",
    "            learning_rate=0.001,\n",
    "            global_step=get_global_step_var(),\n",
    "            decay_steps=468 * 10,\n",
    "            decay_rate=0.3, staircase=True, name='learning_rate')\n",
    "        # for tensorboard.\n",
    "        tf.summary.scalar('lr', lr)\n",
    "        return tf.train.AdamOptimizer(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. main.py\n",
    "#### `logger` for tensorboard, `TrainConfig` for model configuration including model saver.\n",
    "* If you use **auto_set_dir()**, it makes a **`'train_log'`** directory and makes another directory in it \n",
    "   with the same name of file.py. You can see the scalars with tensorboard at there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard and datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:39:11 @logger.py:74]\u001b[0m Argv: /Users/chaeujeong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py -f /Users/chaeujeong/Library/Jupyter/runtime/kernel-52a049b8-c364-424a-b72e-76056a78cf1b.json\n",
      "\u001b[32m[0814 16:39:11 @mnist.py:22]\u001b[0m Downloading to /Users/chaeujeong/tensorpack_data/mnist_data/t10k-images-idx3-ubyte.gz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte.gz: 1.65MB [00:00, 2.18MB/s]                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:39:12 @fs.py:72]\u001b[0m Succesfully downloaded t10k-images-idx3-ubyte.gz. 1648877 bytes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:39:12 @mnist.py:22]\u001b[0m Downloading to /Users/chaeujeong/tensorpack_data/mnist_data/t10k-labels-idx1-ubyte.gz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t10k-labels-idx1-ubyte.gz: 8.19kB [00:00, 18.6kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:39:12 @fs.py:72]\u001b[0m Succesfully downloaded t10k-labels-idx1-ubyte.gz. 4542 bytes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for tensorboard \n",
    "logger.set_logger_dir('./mnist_result')\n",
    "# logger.auto_set_dir() : command 창에서 사용, jupyter 에서는 사용불가.\n",
    "\n",
    "df = get_dataflow(100, 'train')\n",
    "df_test = get_dataflow(100, 'test')\n",
    "\n",
    "df.reset_state()\n",
    "df_test.reset_state()\n",
    "steps_per_epoch = df.size() # 60000/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:41:24 @input_source.py:202]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n",
      "\u001b[32m[0814 16:41:24 @trainers.py:51]\u001b[0m Building graph for a single training tower ...\n",
      "\u001b[32m[0814 16:41:24 @registry.py:121]\u001b[0m conv0 input: [None, 28, 28, 1]\n",
      "\u001b[32m[0814 16:41:24 @registry.py:129]\u001b[0m conv0 output: [None, 28, 28, 32]\n",
      "\u001b[32m[0814 16:41:24 @registry.py:121]\u001b[0m pool0 input: [None, 28, 28, 32]\n",
      "\u001b[32m[0814 16:41:24 @registry.py:129]\u001b[0m pool0 output: [None, 14, 14, 32]\n",
      "\u001b[32m[0814 16:41:24 @registry.py:121]\u001b[0m conv1 input: [None, 14, 14, 32]\n",
      "\u001b[32m[0814 16:41:24 @registry.py:129]\u001b[0m conv1 output: [None, 14, 14, 64]\n",
      "\u001b[32m[0814 16:41:24 @registry.py:121]\u001b[0m pool1 input: [None, 14, 14, 64]\n",
      "\u001b[32m[0814 16:41:24 @registry.py:129]\u001b[0m pool1 output: [None, 7, 7, 64]\n",
      "\u001b[32m[0814 16:41:24 @registry.py:121]\u001b[0m conv2 input: [None, 7, 7, 64]\n",
      "\u001b[32m[0814 16:41:24 @registry.py:129]\u001b[0m conv2 output: [None, 7, 7, 128]\n",
      "\u001b[32m[0814 16:41:24 @registry.py:121]\u001b[0m pool2 input: [None, 7, 7, 128]\n",
      "\u001b[32m[0814 16:41:24 @registry.py:129]\u001b[0m pool2 output: [None, 3, 3, 128]\n",
      "\u001b[32m[0814 16:41:24 @registry.py:121]\u001b[0m fc1 input: [None, 3, 3, 128]\n",
      "\u001b[32m[0814 16:41:24 @registry.py:129]\u001b[0m fc1 output: [None, 10]\n",
      "\u001b[32m[0814 16:41:25 @model_utils.py:64]\u001b[0m \u001b[36mTrainable Variables: \n",
      "\u001b[0mname       shape              dim\n",
      "---------  ---------------  -----\n",
      "conv0/W:0  [3, 3, 1, 32]      288\n",
      "conv0/b:0  [32]                32\n",
      "conv1/W:0  [3, 3, 32, 64]   18432\n",
      "conv1/b:0  [64]                64\n",
      "conv2/W:0  [3, 3, 64, 128]  73728\n",
      "conv2/b:0  [128]              128\n",
      "fc1/W:0    [1152, 10]       11520\n",
      "fc1/b:0    [10]                10\u001b[36m\n",
      "Total #vars=8, #params=104202, size=0.40MB\u001b[0m\n",
      "\u001b[32m[0814 16:41:25 @base.py:187]\u001b[0m Setup callbacks graph ...\n",
      "\u001b[32m[0814 16:41:25 @inference_runner.py:146]\u001b[0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...\n",
      "\u001b[32m[0814 16:41:25 @summary.py:38]\u001b[0m Maintain moving average summary of 2 tensors in collection MOVING_SUMMARY_OPS.\n",
      "\u001b[32m[0814 16:41:25 @summary.py:75]\u001b[0m Summarizing collection 'summaries' of size 4.\n",
      "\u001b[32m[0814 16:41:25 @base.py:205]\u001b[0m Creating the session ...\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\u001b[32m[0814 16:41:25 @base.py:211]\u001b[0m Initializing the session ...\n",
      "\u001b[32m[0814 16:41:25 @base.py:218]\u001b[0m Graph Finalized.\n",
      "\u001b[32m[0814 16:41:25 @concurrency.py:37]\u001b[0m Starting EnqueueThread QueueInput/input_queue ...\n",
      "\u001b[32m[0814 16:41:25 @inference_runner.py:101]\u001b[0m [InferenceRunner] Will eval 100 iterations\n",
      "\u001b[32m[0814 16:41:25 @base.py:250]\u001b[0m Start Epoch 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|600/600[01:26<00:00, 6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:42:52 @base.py:260]\u001b[0m Epoch 1 (global_step 600) finished, time:1 minute 26 seconds.\n",
      "\u001b[32m[0814 16:42:52 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,22.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:42:56 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 16:42:56 @monitor.py:435]\u001b[0m accuracy: 0.60853\n",
      "\u001b[32m[0814 16:42:56 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0814 16:42:56 @monitor.py:435]\u001b[0m train_error: 0.39147\n",
      "\u001b[32m[0814 16:42:56 @monitor.py:435]\u001b[0m validation_Loss: 1.021\n",
      "\u001b[32m[0814 16:42:56 @monitor.py:435]\u001b[0m validation_accuracy: 0.8394\n",
      "\u001b[32m[0814 16:42:56 @group.py:48]\u001b[0m Callbacks took 4.401 sec in total. InferenceRunner: 4.35 seconds\n",
      "\u001b[32m[0814 16:42:56 @base.py:250]\u001b[0m Start Epoch 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:31<00:00, 6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:44:28 @base.py:260]\u001b[0m Epoch 2 (global_step 1200) finished, time:1 minute 31 seconds.\n",
      "\u001b[32m[0814 16:44:28 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-1200.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,23.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:44:32 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 16:44:32 @monitor.py:435]\u001b[0m accuracy: 0.82148\n",
      "\u001b[32m[0814 16:44:32 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0814 16:44:32 @monitor.py:435]\u001b[0m train_error: 0.17852\n",
      "\u001b[32m[0814 16:44:32 @monitor.py:435]\u001b[0m validation_Loss: 0.3877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:44:32 @monitor.py:435]\u001b[0m validation_accuracy: 0.9302\n",
      "\u001b[32m[0814 16:44:32 @group.py:48]\u001b[0m Callbacks took 4.351 sec in total. InferenceRunner: 4.31 seconds\n",
      "\u001b[32m[0814 16:44:32 @base.py:250]\u001b[0m Start Epoch 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|600/600[01:32<00:00, 6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:46:04 @base.py:260]\u001b[0m Epoch 3 (global_step 1800) finished, time:1 minute 32 seconds.\n",
      "\u001b[32m[0814 16:46:04 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-1800.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,20.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:46:09 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 16:46:09 @monitor.py:435]\u001b[0m accuracy: 0.86308\n",
      "\u001b[32m[0814 16:46:09 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0814 16:46:09 @monitor.py:435]\u001b[0m train_error: 0.13692\n",
      "\u001b[32m[0814 16:46:09 @monitor.py:435]\u001b[0m validation_Loss: 0.21717\n",
      "\u001b[32m[0814 16:46:09 @monitor.py:435]\u001b[0m validation_accuracy: 0.9609\n",
      "\u001b[32m[0814 16:46:09 @group.py:48]\u001b[0m Callbacks took 4.898 sec in total. InferenceRunner: 4.86 seconds\n",
      "\u001b[32m[0814 16:46:09 @base.py:250]\u001b[0m Start Epoch 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:34<00:00, 6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:47:44 @base.py:260]\u001b[0m Epoch 4 (global_step 2400) finished, time:1 minute 34 seconds.\n",
      "\u001b[32m[0814 16:47:44 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-2400.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,22.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:47:49 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 16:47:49 @monitor.py:435]\u001b[0m accuracy: 0.89304\n",
      "\u001b[32m[0814 16:47:49 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0814 16:47:49 @monitor.py:435]\u001b[0m train_error: 0.10696\n",
      "\u001b[32m[0814 16:47:49 @monitor.py:435]\u001b[0m validation_Loss: 0.14566\n",
      "\u001b[32m[0814 16:47:49 @monitor.py:435]\u001b[0m validation_accuracy: 0.9696\n",
      "\u001b[32m[0814 16:47:49 @group.py:48]\u001b[0m Callbacks took 4.704 sec in total. InferenceRunner: 4.66 seconds\n",
      "\u001b[32m[0814 16:47:49 @base.py:250]\u001b[0m Start Epoch 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:36<00:00, 6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:49:26 @base.py:260]\u001b[0m Epoch 5 (global_step 3000) finished, time:1 minute 36 seconds.\n",
      "\u001b[32m[0814 16:49:26 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-3000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,22.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:49:30 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 16:49:30 @monitor.py:435]\u001b[0m accuracy: 0.91565\n",
      "\u001b[32m[0814 16:49:30 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0814 16:49:30 @monitor.py:435]\u001b[0m train_error: 0.084347\n",
      "\u001b[32m[0814 16:49:30 @monitor.py:435]\u001b[0m validation_Loss: 0.10987\n",
      "\u001b[32m[0814 16:49:30 @monitor.py:435]\u001b[0m validation_accuracy: 0.9775\n",
      "\u001b[32m[0814 16:49:30 @group.py:48]\u001b[0m Callbacks took 4.501 sec in total. InferenceRunner: 4.47 seconds\n",
      "\u001b[32m[0814 16:49:30 @base.py:250]\u001b[0m Start Epoch 6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:27<00:00, 7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:50:58 @base.py:260]\u001b[0m Epoch 6 (global_step 3600) finished, time:1 minute 27 seconds.\n",
      "\u001b[32m[0814 16:50:58 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-3600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,23.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:51:02 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 16:51:02 @monitor.py:435]\u001b[0m accuracy: 0.91845\n",
      "\u001b[32m[0814 16:51:02 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0814 16:51:02 @monitor.py:435]\u001b[0m train_error: 0.081546\n",
      "\u001b[32m[0814 16:51:02 @monitor.py:435]\u001b[0m validation_Loss: 0.09271\n",
      "\u001b[32m[0814 16:51:02 @monitor.py:435]\u001b[0m validation_accuracy: 0.9806\n",
      "\u001b[32m[0814 16:51:02 @group.py:48]\u001b[0m Callbacks took 4.359 sec in total. InferenceRunner: 4.33 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:51:02 @base.py:250]\u001b[0m Start Epoch 7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|600/600[01:36<00:00, 7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:52:39 @base.py:260]\u001b[0m Epoch 7 (global_step 4200) finished, time:1 minute 36 seconds.\n",
      "\u001b[32m[0814 16:52:39 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-4200.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,23.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:52:43 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 16:52:43 @monitor.py:435]\u001b[0m accuracy: 0.93461\n",
      "\u001b[32m[0814 16:52:43 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0814 16:52:43 @monitor.py:435]\u001b[0m train_error: 0.065392\n",
      "\u001b[32m[0814 16:52:43 @monitor.py:435]\u001b[0m validation_Loss: 0.078173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:52:43 @monitor.py:435]\u001b[0m validation_accuracy: 0.9829\n",
      "\u001b[32m[0814 16:52:43 @group.py:48]\u001b[0m Callbacks took 4.334 sec in total. InferenceRunner: 4.29 seconds\n",
      "\u001b[32m[0814 16:52:43 @base.py:250]\u001b[0m Start Epoch 8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|600/600[01:31<00:00, 6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:54:15 @base.py:260]\u001b[0m Epoch 8 (global_step 4800) finished, time:1 minute 31 seconds.\n",
      "\u001b[32m[0814 16:54:15 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-4800.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,24.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:54:19 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 16:54:19 @monitor.py:435]\u001b[0m accuracy: 0.94347\n",
      "\u001b[32m[0814 16:54:19 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0814 16:54:19 @monitor.py:435]\u001b[0m train_error: 0.056533\n",
      "\u001b[32m[0814 16:54:19 @monitor.py:435]\u001b[0m validation_Loss: 0.070159\n",
      "\u001b[32m[0814 16:54:19 @monitor.py:435]\u001b[0m validation_accuracy: 0.9851\n",
      "\u001b[32m[0814 16:54:19 @group.py:48]\u001b[0m Callbacks took 4.158 sec in total. InferenceRunner: 4.13 seconds\n",
      "\u001b[32m[0814 16:54:19 @base.py:250]\u001b[0m Start Epoch 9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:35<00:00, 6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:55:55 @base.py:260]\u001b[0m Epoch 9 (global_step 5400) finished, time:1 minute 35 seconds.\n",
      "\u001b[32m[0814 16:55:55 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-5400.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:05<00:00,19.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:56:00 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 16:56:00 @monitor.py:435]\u001b[0m accuracy: 0.94025\n",
      "\u001b[32m[0814 16:56:00 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0814 16:56:00 @monitor.py:435]\u001b[0m train_error: 0.059746\n",
      "\u001b[32m[0814 16:56:00 @monitor.py:435]\u001b[0m validation_Loss: 0.065854\n",
      "\u001b[32m[0814 16:56:00 @monitor.py:435]\u001b[0m validation_accuracy: 0.9845\n",
      "\u001b[32m[0814 16:56:00 @group.py:48]\u001b[0m Callbacks took 5.183 sec in total. InferenceRunner: 5.14 seconds\n",
      "\u001b[32m[0814 16:56:00 @base.py:250]\u001b[0m Start Epoch 10 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:23<00:00, 7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:57:23 @base.py:260]\u001b[0m Epoch 10 (global_step 6000) finished, time:1 minute 23 seconds.\n",
      "\u001b[32m[0814 16:57:23 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-6000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,23.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:57:28 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 16:57:28 @monitor.py:435]\u001b[0m accuracy: 0.94362\n",
      "\u001b[32m[0814 16:57:28 @monitor.py:435]\u001b[0m lr: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 16:57:28 @monitor.py:435]\u001b[0m train_error: 0.056378\n",
      "\u001b[32m[0814 16:57:28 @monitor.py:435]\u001b[0m validation_Loss: 0.063275\n",
      "\u001b[32m[0814 16:57:28 @monitor.py:435]\u001b[0m validation_accuracy: 0.9854\n",
      "\u001b[32m[0814 16:57:28 @group.py:48]\u001b[0m Callbacks took 4.357 sec in total. InferenceRunner: 4.31 seconds\n",
      "\u001b[32m[0814 16:57:28 @base.py:264]\u001b[0m Training has finished!\n",
      "\u001b[32m[0814 16:57:28 @input_source.py:157]\u001b[0m EnqueueThread QueueInput/input_queue Exited.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration containing everything necessary in a training.\n",
    "\"\"\"\n",
    "config = TrainConfig(\n",
    "    model = Model(),\n",
    "    data = QueueInput(df), # 상황에 따라서 ZMQ사용도 가능, \n",
    "    callbacks = [\n",
    "        # save the model after every epoch\n",
    "        ModelSaver(checkpoint_dir='./mnist_result'),\n",
    "        InferenceRunner(\n",
    "            df_test,\n",
    "            ScalarStats(['Loss', 'accuracy'])),\n",
    "#         ScheduledHyperParamSetter('learning_rate',\n",
    "#                                   [(1, 0.1), \n",
    "#                                    (300, 0.01), \n",
    "#                                    (500, 0.001)]) # : 특정 epoch에서 lr을 크게 하거나 줄여라.\n",
    "    ],\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    max_epoch = 10,\n",
    ")\n",
    "\n",
    "# training with CPU or GPU?\n",
    "if tf.test.gpu_device_name():\n",
    "    launch_train_with_config(config, SyncMultiGPUTrainer(4)) # # of GPU\n",
    "else:\n",
    "    launch_train_with_config(config, SimpleTrainer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Loading The Saved Model \n",
    "#### Loading saved model and learning 5 epochs more.\n",
    "##### In tensorflow, \n",
    "* **`.meta`** file means **the structure** of model, \n",
    "    all **variables, and operations.** \n",
    "* **`index`** means a binary file contating **weights, biases, and gradients**.\n",
    "\n",
    "* We are going to use **`PredictConfig`** to evaluate the loaded and more trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:00:03 @varmanip.py:182]\u001b[0m Checkpoint path ./mnist_result/model-6000.index is auto-corrected to ./mnist_result/model-6000.\n",
      "\u001b[32m[0814 17:00:03 @config.py:215]\u001b[0m Found checkpoint at ./mnist_result/model-6000. session_init arguments will be overwritten.\n",
      "\u001b[32m[0814 17:00:03 @config.py:225]\u001b[0m Found history statistics from JSON. Overwrite the starting epoch to epoch #11.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Graph is finalized and cannot be modified.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9651926c6699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mlaunch_train_with_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimpleTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorpack/train/interface.py\u001b[0m in \u001b[0;36mlaunch_train_with_config\u001b[0;34m(config, trainer)\u001b[0m\n\u001b[1;32m     83\u001b[0m     trainer.setup_graph(\n\u001b[1;32m     84\u001b[0m         \u001b[0minputs_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         model._build_graph_get_cost, model.get_optimizer)\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0m_check_unused_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     trainer.train_with_defaults(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorpack/utils/argtools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0m_FUNC_CALLED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorpack/train/tower.py\u001b[0m in \u001b[0;36msetup_graph\u001b[0;34m(self, inputs_desc, input, get_cost_fn, get_opt_fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# TODO setup may want to register monitor as well??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0minput_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0mtrain_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_cost_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_opt_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_callbacks\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorpack/train/tower.py\u001b[0m in \u001b[0;36m_setup_input\u001b[0;34m(self, inputs_desc, input)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_get_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_cost_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_opt_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorpack/utils/argtools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0m_FUNC_CALLED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorpack/input_source/input_source_base.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, inputs_desc)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mcallbacks\u001b[0m \u001b[0mof\u001b[0m \u001b[0mInputSource\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0muse\u001b[0m \u001b[0many\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \"\"\"\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorpack/input_source/input_source.py\u001b[0m in \u001b[0;36m_setup\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_placehdrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_placeholder_reuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_placehdrs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;34m\"QueueInput has to be used with some inputs!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorpack/input_source/input_source.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_placehdrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_placeholder_reuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_placehdrs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;34m\"QueueInput has to be used with some inputs!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorpack/graph_builder/model_desc.py\u001b[0m in \u001b[0;36mbuild_placeholder_reuse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_placeholder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_placeholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_register_cached_placeholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorpack/graph_builder/model_desc.py\u001b[0m in \u001b[0;36mbuild_placeholder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# clear any name scope it might get called in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             ret = tf.placeholder(\n\u001b[0;32m---> 51\u001b[0;31m                 self.type, shape=self.shape, name=self.name)\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_cached_placeholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   1732\u001b[0m                        \"eager execution.\")\n\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1734\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   4922\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4923\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 4924\u001b[0;31m         \"Placeholder\", dtype=dtype, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   4925\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4926\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3385\u001b[0m     \"\"\"\n\u001b[0;32m-> 3386\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_not_finalized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3387\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3388\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_check_not_finalized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3022\u001b[0m     \"\"\"\n\u001b[1;32m   3023\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Graph is finalized and cannot be modified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Graph is finalized and cannot be modified."
     ]
    }
   ],
   "source": [
    "config = AutoResumeTrainConfig(\n",
    "    model = Model(),\n",
    "    session_init = get_model_loader('./mnist_result/model-6000.index'),\n",
    "    data = QueueInput(df),\n",
    "    callbacks = [\n",
    "        # save the model after every epoch\n",
    "        ModelSaver(checkpoint_dir='./mnist_result/transfer'),\n",
    "        InferenceRunner(\n",
    "            df_test,\n",
    "            ScalarStats(['Loss', 'accuracy'])),\n",
    "#         ScheduledHyperParamSetter('learning_rate',\n",
    "#                                   [(1, 0.1), \n",
    "#                                    (300, 0.01), \n",
    "#                                    (500, 0.001)])\n",
    "    ],\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    max_epoch = 5,\n",
    ")\n",
    "\n",
    "launch_train_with_config(config, SimpleTrainer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "session = get_model_loader('./mnist_result/model-6000.index')\n",
    "\n",
    "pred_config = PredictConfig(\n",
    "        model=model,\n",
    "        session_init=session,\n",
    "        input_names=['input', 'label'], # class Model-inputs\n",
    "        output_names=['accuracy', 'Loss'] # class Model-build_graph\n",
    "    )\n",
    "pred = SimpleDatasetPredictor(pred_config, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0.0\n",
    "total_loss = 0.0\n",
    "\n",
    "for i, (acc, loss) in enumerate(pred.get_result()): # 각 batch마다 pred에서 get_result\n",
    "    accuracy += acc \n",
    "    total_loss += loss\n",
    "    \n",
    "print(\"Accuracy: {:0.3f}\".format(accuracy/(i+1)))\n",
    "print(\"Loss: {:0.3f}\".format(total_loss/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
